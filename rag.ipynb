{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\subject projects\\RAG\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HospitalRAGProcessor:\n",
    "    def __init__(self, api_key: str, db_path: str):\n",
    "        self.api_key = api_key\n",
    "        self.db_path = db_path\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=self.api_key,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "        \n",
    "    def prepare_documents(self, data: List[dict]) -> List[Document]:\n",
    "        \"\"\"Convert raw data into LangChain Document objects.\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for doc in data:\n",
    "            if not isinstance(doc, dict):\n",
    "                print(f\"Invalid document format: {doc}\")\n",
    "                continue\n",
    "                \n",
    "            # Convert keywords list to string if present\n",
    "            keywords = doc.get(\"metadata\", {}).get(\"keywords\", [])\n",
    "            if isinstance(keywords, list):\n",
    "                keywords = \", \".join(keywords)\n",
    "                \n",
    "            metadata = {\n",
    "                \"title\": doc.get(\"title\", \"\"),\n",
    "                \"category\": doc.get(\"category\", \"\"),\n",
    "                \"keywords\": keywords,\n",
    "                \"id\": doc.get(\"id\", \"\")\n",
    "            }\n",
    "            \n",
    "            # Create LangChain Document object\n",
    "            if content := doc.get(\"content\"):\n",
    "                documents.append(\n",
    "                    Document(\n",
    "                        page_content=content,\n",
    "                        metadata=metadata\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Document {doc.get('id')} has no content. Skipping...\")\n",
    "                \n",
    "        return documents\n",
    "    \n",
    "    def split_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"Split documents into smaller chunks if needed.\"\"\"\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len,\n",
    "        )\n",
    "        return text_splitter.split_documents(documents)\n",
    "    \n",
    "    def create_vector_store(self, documents: List[Document], collection_name: str):\n",
    "        \"\"\"Create and persist the vector store.\"\"\"\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=os.path.join(self.db_path, collection_name),\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        vector_store.persist()\n",
    "        return vector_store\n",
    "    \n",
    "    def process_and_store_documents(self, data: List[dict], collection_name: str):\n",
    "        \"\"\"Main method to process and store documents.\"\"\"\n",
    "        # Prepare documents\n",
    "        documents = self.prepare_documents(data)\n",
    "        \n",
    "        # Split documents if needed\n",
    "        split_docs = self.split_documents(documents)\n",
    "        \n",
    "        # Create and persist vector store\n",
    "        vector_store = self.create_vector_store(split_docs, collection_name)\n",
    "        \n",
    "        return vector_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database():\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Load data\n",
    "    with open('data_set.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = HospitalRAGProcessor(\n",
    "        api_key=os.getenv('API_KEY'),\n",
    "        db_path=\"./database\"\n",
    "    )\n",
    "    \n",
    "    # Process and store documents\n",
    "    vector_store = processor.process_and_store_documents(\n",
    "        data=data,\n",
    "        collection_name=\"hospital_documents_langchain\"\n",
    "    )\n",
    "    \n",
    "    print(\"Vector store created successfully!\")\n",
    "    return vector_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_39676\\1137882033.py:62: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_store.persist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x275f2dda870>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory,RunnableLambda\n",
    "from langchain_google_genai import GoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='AIzaSyCGsj7XUUDktYTIqS3ITCOIk54oN7OD9dw'\n",
    "db_path=\"./database\"\n",
    "collection_name=\"hospital_documents_langchain\"\n",
    "\n",
    "llm = GoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            google_api_key=api_key,\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=api_key,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "\n",
    "retriever = Chroma(\n",
    "            persist_directory= os.path.join(db_path, collection_name),\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=collection_name\n",
    "        ).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are a friendly customer service agent working for Horizon Hospitals Lanka PLC. \n",
    "            Your goal is to assist with any questions using the most relevant and up-to-date information provided in the context below. \n",
    "            When responding, ensure you:\n",
    "            \n",
    "            Previous conversation history:\n",
    "\n",
    "            - Keep your tone warm, professional, and helpful, just as a caring hospital representative would.\n",
    "            - Provide detailed and accurate answers, incorporating only relevant data from the context.\n",
    "            - If the information doesn't directly address the question, acknowledge that politely and offer a general response if appropriate.\n",
    "            - Avoid making up answers if the data does not apply. It's better to admit that the information is not available than to provide inaccurate information and mention to contact hospital via phone.\n",
    "            \n",
    "            Context: {context}\n",
    "\n",
    "            Based on the context, craft a thoughtful, precise, and helpful response:\n",
    "            \"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello!  The name of our hospital is Horizon Hospitals Lanka PLC. We're here to help in any way we can.  ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is the name of the hospital?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
