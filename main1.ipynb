{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HospitalRAGProcessor:\n",
    "    def __init__(self, api_key: str, db_path: str):\n",
    "        self.api_key = api_key\n",
    "        self.db_path = db_path\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=self.api_key,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "        \n",
    "    def prepare_documents(self, data: List[dict]) -> List[Document]:\n",
    "        \"\"\"Convert raw data into LangChain Document objects.\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for doc in data:\n",
    "            if not isinstance(doc, dict):\n",
    "                print(f\"Invalid document format: {doc}\")\n",
    "                continue\n",
    "                \n",
    "            # Convert keywords list to string if present\n",
    "            keywords = doc.get(\"metadata\", {}).get(\"keywords\", [])\n",
    "            if isinstance(keywords, list):\n",
    "                keywords = \", \".join(keywords)\n",
    "                \n",
    "            metadata = {\n",
    "                \"title\": doc.get(\"title\", \"\"),\n",
    "                \"category\": doc.get(\"category\", \"\"),\n",
    "                \"keywords\": keywords,\n",
    "                \"id\": doc.get(\"id\", \"\")\n",
    "            }\n",
    "            \n",
    "            # Create LangChain Document object\n",
    "            if content := doc.get(\"content\"):\n",
    "                documents.append(\n",
    "                    Document(\n",
    "                        page_content=content,\n",
    "                        metadata=metadata\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Document {doc.get('id')} has no content. Skipping...\")\n",
    "                \n",
    "        return documents\n",
    "    \n",
    "    def split_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"Split documents into smaller chunks if needed.\"\"\"\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len,\n",
    "        )\n",
    "        return text_splitter.split_documents(documents)\n",
    "    \n",
    "    def create_vector_store(self, documents: List[Document], collection_name: str):\n",
    "        \"\"\"Create and persist the vector store.\"\"\"\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=os.path.join(self.db_path, collection_name),\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        vector_store.persist()\n",
    "        return vector_store\n",
    "    \n",
    "    def process_and_store_documents(self, data: List[dict], collection_name: str):\n",
    "        \"\"\"Main method to process and store documents.\"\"\"\n",
    "        # Prepare documents\n",
    "        documents = self.prepare_documents(data)\n",
    "        \n",
    "        # Split documents if needed\n",
    "        split_docs = self.split_documents(documents)\n",
    "        \n",
    "        # Create and persist vector store\n",
    "        vector_store = self.create_vector_store(split_docs, collection_name)\n",
    "        \n",
    "        return vector_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database():\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Load data\n",
    "    with open('data_set.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = HospitalRAGProcessor(\n",
    "        api_key=os.getenv('API_KEY'),\n",
    "        db_path=\"D:\\\\subject projects\\\\RAG\\\\database\"\n",
    "    )\n",
    "    \n",
    "    # Process and store documents\n",
    "    vector_store = processor.process_and_store_documents(\n",
    "        data=data,\n",
    "        collection_name=\"hospital_documents_langchain1\"\n",
    "    )\n",
    "    \n",
    "    print(\"Vector store created successfully!\")\n",
    "    return vector_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1d780184770>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "class HospitalRAGQuerySystem:\n",
    "    def __init__(self, api_key: str, db_path: str, collection_name: str):\n",
    "        self.api_key = api_key\n",
    "        self.db_path = db_path\n",
    "        self.collection_name = collection_name\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=self.api_key,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "        \n",
    "        # Initialize LLM\n",
    "        self.llm = GoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            google_api_key=self.api_key,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Load vector store\n",
    "        self.vector_store = Chroma(\n",
    "            persist_directory=os.path.join(db_path, collection_name),\n",
    "            embedding_function=self.embeddings,\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "        \n",
    "        # Define custom prompt template\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            template=\"\"\"You are a friendly customer service agent working for Horizon Hospitals Lanka PLC. \n",
    "            Your goal is to assist with any questions using the most relevant and up-to-date information provided in the context below. \n",
    "            When responding, ensure you:\n",
    "            \n",
    "            Previous conversation history:\n",
    "\n",
    "            - Keep your tone warm, professional, and helpful, just as a caring hospital representative would.\n",
    "            - Provide detailed and accurate answers, incorporating only relevant data from the context.\n",
    "            - If the information doesn't directly address the question, acknowledge that politely and offer a general response if appropriate.\n",
    "            - Avoid making up answers if the data does not apply. It's better to admit that the information is not available than to provide inaccurate information and mention to contact hospital via phone.\n",
    "            \n",
    "            Context: {context}\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Based on the context, craft a thoughtful, precise, and helpful response:\n",
    "            \"\"\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "        \n",
    "        # Initialize RAG chain\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={\"prompt\": self.prompt_template}\n",
    "        )\n",
    "    \n",
    "    def answer_query(self, query: str) -> dict:\n",
    "        \"\"\"\n",
    "        Process a query and return the answer along with source documents.\n",
    "        \"\"\"\n",
    "        response = self.qa_chain({\"query\": query})\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response[\"result\"]\n",
    "        }\n",
    "        \n",
    "    def clear_memory(self):\n",
    "        \"\"\"\n",
    "        Clear the conversation memory when needed\n",
    "        \"\"\"\n",
    "        self.memory.clear()\n",
    "    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query):\n",
    "    # Initialize the system\n",
    "    rag_system = HospitalRAGQuerySystem(\n",
    "        api_key='AIzaSyCGsj7XUUDktYTIqS3ITCOIk54oN7OD9dw',\n",
    "        db_path=\"D:\\\\subject projects\\\\RAG\\\\database\",\n",
    "        collection_name=\"hospital_documents_langchain\"\n",
    "    )\n",
    "   \n",
    "    print(f\"\\nQuestion: {query}\")\n",
    "    response = rag_system.answer_query(query)\n",
    "    print(f\"Answer: {response['answer']}\")\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: what are your services\n",
      "Answer: Hello there! I'm happy to help. While the information provided focuses on our commitment to quality and affordability, it doesn't specifically list our services.  To get a complete list of the services we offer, I recommend contacting us directly at 011 1234567 or emailing us at info@HorizonHealth.com. We'd be happy to provide you with more details. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(\"what are your services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: how to schedule an appointment\n",
      "Answer: Hello there! To schedule an appointment with a doctor, you can either visit our website and go to the \"Channel Doctor\" section or call our reception at 011 1234567.  The available appointment slots are listed in the \"Channel Doctor\" section on our website. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(\"how to schedule an appointment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: what are the services provide by heart centre\n",
      "Answer: Our Heart Centre at Horizon Hospitals Lanka PLC offers a wide range of services to address your cardiac needs. We provide both diagnostic and treatment options, including:\n",
      "\n",
      "**Diagnostic Services:**\n",
      "\n",
      "* **Electrocardiogram (ECG)**\n",
      "* **Echocardiography**\n",
      "* **Exercise stress test (Treadmill test)**\n",
      "* **Holter monitor**\n",
      "* **Stress Echo (Dobutamine)**\n",
      "* **Ambulatory BP Tec 99 Scan (in collaboration with Nuclear Medicine Department)**\n",
      "\n",
      "**Treatment Services:**\n",
      "\n",
      "* **Angiogram**\n",
      "* **Angioplasty (Stent placement)**\n",
      "* **Device Closure**\n",
      "* **Valvuloplasty**\n",
      "* **Placement of pacemakers (PPM) and implantable cardio defibrillators for abnormal heart rhythms (ICD)**\n",
      "* **Cardiac Re synchronization Therapy (CRT)**\n",
      "* **Rotablator**\n",
      "* **Fractional Flow Reserve (FFR) Measurement**\n",
      "* **Coronary Artery Bypass Graft (CABG)**\n",
      "* **On pump/ off pump Redo Surgery**\n",
      "* **Cardiac Total Revascularisation**\n",
      "* **Aortic Dissection Valve/Arterial Switch Procedures**\n",
      "* **Atrial Septal Defect (ASD)**\n",
      "* **Tetralogy of Fallot (TOF)**\n",
      "* **Valve repair and replacement surgery**\n",
      "* **Surgical Closure of Atrial Septal Defect**\n",
      "* **Congenital Heart Disease Correction Surgery**\n",
      "\n",
      "We also offer comprehensive support services including:\n",
      "\n",
      "* **Blood Bank**\n",
      "* **Physiotherapist**\n",
      "* **Dietitian**\n",
      "* **Pharmacist**\n",
      "* **Laboratory services**\n",
      "\n",
      "Our dedicated team of specialists and state-of-the-art facilities ensure you receive the highest quality cardiac care. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(\"what are the services provide by heart centre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory,RunnableLambda\n",
    "from langchain_google_genai import GoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='AIzaSyCGsj7XUUDktYTIqS3ITCOIk54oN7OD9dw'\n",
    "db_path=\"D:\\\\subject projects\\\\RAG\\\\database\"\n",
    "collection_name=\"hospital_documents_langchain\"\n",
    "\n",
    "llm = GoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            google_api_key=api_key,\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=api_key,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "\n",
    "retriever = Chroma(\n",
    "            persist_directory= os.path.join(db_path, collection_name),\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=collection_name\n",
    "        ).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer question ###\n",
    "qa_system_prompt = \"\"\"You are a friendly customer service agent working for Horizon Hospitals Lanka PLC. \n",
    "            Your goal is to assist with any questions using the most relevant and up-to-date information provided in the context below. \n",
    "            When responding, ensure you:\n",
    "            \n",
    "            Previous conversation history:\n",
    "\n",
    "            - Keep your tone warm, professional, and helpful, just as a caring hospital representative would.\n",
    "            - Provide detailed and accurate answers, incorporating only relevant data from the context.\n",
    "            - If the information doesn't directly address the question, acknowledge that politely and offer a general response if appropriate.\n",
    "            - Avoid making up answers if the data does not apply. It's better to admit that the information is not available than to provide inaccurate information and mention to contact hospital via phone.\n",
    "            \n",
    "            Context: {context}\n",
    "\n",
    "            Based on the context, craft a thoughtful, precise, and helpful response:\n",
    "            \"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there!  The name of our hospital is Horizon Hospitals Lanka PLC. We're here to help in any way we can.  Is there anything else I can assist you with today? \\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is the name of the hospital?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
